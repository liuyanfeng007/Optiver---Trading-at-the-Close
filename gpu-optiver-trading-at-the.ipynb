{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4e0abc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-24T00:51:54.246452Z",
     "iopub.status.busy": "2023-10-24T00:51:54.245684Z",
     "iopub.status.idle": "2023-10-24T00:51:54.249755Z",
     "shell.execute_reply": "2023-10-24T00:51:54.249125Z"
    },
    "papermill": {
     "duration": 0.010595,
     "end_time": "2023-10-24T00:51:54.251508",
     "exception": false,
     "start_time": "2023-10-24T00:51:54.240913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip uninstall -y lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d8c66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:51:54.259426Z",
     "iopub.status.busy": "2023-10-24T00:51:54.259000Z",
     "iopub.status.idle": "2023-10-24T00:52:26.700642Z",
     "shell.execute_reply": "2023-10-24T00:52:26.699541Z"
    },
    "papermill": {
     "duration": 32.4481,
     "end_time": "2023-10-24T00:52:26.703024",
     "exception": false,
     "start_time": "2023-10-24T00:51:54.254924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (3.3.2)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm) (0.40.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.23.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.11.2)\r\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm --config-settings=cmake.define.USE_GPU=ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758bfe91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:52:26.711504Z",
     "iopub.status.busy": "2023-10-24T00:52:26.711187Z",
     "iopub.status.idle": "2023-10-24T00:52:31.383247Z",
     "shell.execute_reply": "2023-10-24T00:52:31.382487Z"
    },
    "papermill": {
     "duration": 4.678922,
     "end_time": "2023-10-24T00:52:31.385577",
     "exception": false,
     "start_time": "2023-10-24T00:52:26.706655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from warnings import simplefilter\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "is_train = True\n",
    "is_infer = True\n",
    "N_Folds = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61da704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:52:31.394412Z",
     "iopub.status.busy": "2023-10-24T00:52:31.393833Z",
     "iopub.status.idle": "2023-10-24T00:53:06.804085Z",
     "shell.execute_reply": "2023-10-24T00:53:06.803233Z"
    },
    "papermill": {
     "duration": 35.417058,
     "end_time": "2023-10-24T00:53:06.806508",
     "exception": false,
     "start_time": "2023-10-24T00:52:31.389450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "\n",
    "#整体特征\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].std() + train.groupby('stock_id')['ask_size'].std()\n",
    "max_sizes = train.groupby('stock_id')['bid_size'].max() + train.groupby('stock_id')['ask_size'].max()\n",
    "min_sizes = train.groupby('stock_id')['bid_size'].min() + train.groupby('stock_id')['ask_size'].min()\n",
    "mean_sizes = train.groupby('stock_id')['bid_size'].mean() + train.groupby('stock_id')['ask_size'].mean()\n",
    "first_sizes = train.groupby('stock_id')['bid_size'].first() + train.groupby('stock_id')['ask_size'].first()\n",
    "last_sizes = train.groupby('stock_id')['bid_size'].last() + train.groupby('stock_id')['ask_size'].last()\n",
    "quantile_dic = {}\n",
    "for q in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    quantile_dic[\"quantile\" + str(q)] = train.groupby('stock_id')['bid_size'].quantile(q)\n",
    "#可以再做日期的（好像没看到drop掉日期列）\n",
    "#date_median_sizes = train.groupby('date_id')['bid_size'].median() + train.groupby('date_id')['ask_size'].median()\n",
    "#date_std_sizes = train.groupby('date_id')['bid_size'].std() + train.groupby('date_id')['ask_size'].std()\n",
    "#date_max_sizes = train.groupby('date_id')['bid_size'].max() + train.groupby('date_id')['ask_size'].max()\n",
    "#date_min_sizes = train.groupby('date_id')['bid_size'].min() + train.groupby('date_id')['ask_size'].min()\n",
    "#date_mean_sizes = train.groupby('date_id')['bid_size'].mean() + train.groupby('date_id')['ask_size'].mean()\n",
    "#date_quantile_dic = {}\n",
    "#for q in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "#    date_quantile_dic[\"quantile\" + str(q)] = train.groupby('date_id')['bid_size'].quantile(q)\n",
    "    \n",
    "train = train.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9034a3b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:53:06.815412Z",
     "iopub.status.busy": "2023-10-24T00:53:06.815145Z",
     "iopub.status.idle": "2023-10-24T00:53:06.828899Z",
     "shell.execute_reply": "2023-10-24T00:53:06.828090Z"
    },
    "papermill": {
     "duration": 0.020401,
     "end_time": "2023-10-24T00:53:06.830807",
     "exception": false,
     "start_time": "2023-10-24T00:53:06.810406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_eng(df):\n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'date_id','time_id']]\n",
    "    df = df[cols]\n",
    "    \n",
    "    #匹配失败数量和匹配成功数量的比率\n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    #供需市场的差额\n",
    "    df['bid_ask_volume_diff'] = df['ask_size'] - df['bid_size']\n",
    "    #供需市场总和\n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + df['ask_size']\n",
    "    \n",
    "    #供需价格的均值\n",
    "    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n",
    "    \n",
    "    #整体数据情况\n",
    "    df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "    df['max_size'] = df['stock_id'].map(max_sizes.to_dict())\n",
    "    df['min_size'] = df['stock_id'].map(min_sizes.to_dict())\n",
    "    df['mean_size'] = df['stock_id'].map(mean_sizes.to_dict())\n",
    "    df['first_size'] = df['stock_id'].map(first_sizes.to_dict())    \n",
    "    df['last_size'] = df['stock_id'].map(last_sizes.to_dict())       \n",
    "    for q in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "        df[\"quantile\" + str(q)] =  df['stock_id'].map(quantile_dic[\"quantile\" + str(q)].to_dict()) \n",
    "    #可以再做日期的\n",
    "    #df['date_median_size'] = df['date_id'].map(date_median_sizes.to_dict())\n",
    "    #df['date_std_size'] = df['date_id'].map(date_std_sizes.to_dict())\n",
    "    #df['date_max_size'] = df['date_id'].map(date_max_sizes.to_dict())\n",
    "    #df['date_min_size'] = df['date_id'].map(date_min_sizes.to_dict())\n",
    "    #df['date_mean_size'] = df['date_id'].map(date_mean_sizes.to_dict())       \n",
    "    #for q in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    #    df[\"date_date_quantile\" + str(q)] =  df['date_id'].map(date_quantile_dic[\"quantile\" + str(q)].to_dict())     \n",
    "    \n",
    "    #整体市场规模和当前的市场规模比较\n",
    "    df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0)\n",
    "    \n",
    "    prices = ['reference_price', 'far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    #价格之间做差，做差/求和\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]} - {c[1]})/({c[0]} + {c[1]})')\n",
    "        \n",
    "    for c in combinations(prices, 3):\n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1) - min_ - max_\n",
    "        \n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc3f632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:53:06.838741Z",
     "iopub.status.busy": "2023-10-24T00:53:06.838493Z",
     "iopub.status.idle": "2023-10-24T00:54:39.585072Z",
     "shell.execute_reply": "2023-10-24T00:54:39.584148Z"
    },
    "papermill": {
     "duration": 92.756367,
     "end_time": "2023-10-24T00:54:39.590668",
     "exception": false,
     "start_time": "2023-10-24T00:53:06.834301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparams = {\\n    'learning_rate': 0.009,#0.009,#0.018,\\n    'max_depth': 13,#10,#9,\\n    'n_estimators': 1400,#600,\\n    'num_leaves': 500,#440,\\n    'objective': 'mae',\\n    'random_state': 43,\\n    'reg_alpha': 0.01,\\n    'reg_lambda': 0.01,\\n    #'device': 'gpu'\\n}\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['target'].values\n",
    "X = feature_eng(train.drop(columns='target'))\n",
    "\n",
    "y_min = np.min(y)\n",
    "y_max = np.max(y)\n",
    "'''\n",
    "params = {\n",
    "    'learning_rate': 0.009,#0.009,#0.018,\n",
    "    'max_depth': 13,#10,#9,\n",
    "    'n_estimators': 1400,#600,\n",
    "    'num_leaves': 500,#440,\n",
    "    'objective': 'mae',\n",
    "    'random_state': 43,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    #'device': 'gpu'\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fedd091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:54:39.598938Z",
     "iopub.status.busy": "2023-10-24T00:54:39.598669Z",
     "iopub.status.idle": "2023-10-24T00:54:39.603393Z",
     "shell.execute_reply": "2023-10-24T00:54:39.602573Z"
    },
    "papermill": {
     "duration": 0.011075,
     "end_time": "2023-10-24T00:54:39.605247",
     "exception": false,
     "start_time": "2023-10-24T00:54:39.594172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "'learning_rate': 0.009,#0.009,#0.018,\n",
    "'max_depth': 13,#10,#9,\n",
    "'n_estimators': 900,#600,\n",
    "'num_leaves': 500,#440,\n",
    "'objective': 'mae',\n",
    "'random_state': 43,\n",
    "'reg_alpha': 0.01,\n",
    "'reg_lambda': 0.01,\n",
    "################################################    \n",
    " \"device\": \"gpu\",\n",
    " \"gpu_platform_id\": 0,\n",
    " \"gpu_device_id\": 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829590b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T00:54:39.613280Z",
     "iopub.status.busy": "2023-10-24T00:54:39.612850Z",
     "iopub.status.idle": "2023-10-24T01:42:12.275548Z",
     "shell.execute_reply": "2023-10-24T01:42:12.274563Z"
    },
    "papermill": {
     "duration": 2852.685476,
     "end_time": "2023-10-24T01:42:12.294174",
     "exception": false,
     "start_time": "2023-10-24T00:54:39.608698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19778\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.231481 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.32876\tvalid_1's l1: 6.34572\n",
      "[100]\ttraining's l1: 6.29033\tvalid_1's l1: 6.31147\n",
      "[150]\ttraining's l1: 6.26858\tvalid_1's l1: 6.2937\n",
      "[200]\ttraining's l1: 6.25413\tvalid_1's l1: 6.28325\n",
      "[250]\ttraining's l1: 6.24319\tvalid_1's l1: 6.27621\n",
      "[300]\ttraining's l1: 6.23362\tvalid_1's l1: 6.27061\n",
      "[350]\ttraining's l1: 6.22428\tvalid_1's l1: 6.26508\n",
      "[400]\ttraining's l1: 6.21532\tvalid_1's l1: 6.25987\n",
      "[450]\ttraining's l1: 6.20709\tvalid_1's l1: 6.25554\n",
      "[500]\ttraining's l1: 6.1992\tvalid_1's l1: 6.25159\n",
      "[550]\ttraining's l1: 6.19134\tvalid_1's l1: 6.24742\n",
      "[600]\ttraining's l1: 6.18385\tvalid_1's l1: 6.24355\n",
      "[650]\ttraining's l1: 6.17692\tvalid_1's l1: 6.24012\n",
      "[700]\ttraining's l1: 6.17028\tvalid_1's l1: 6.23699\n",
      "[750]\ttraining's l1: 6.16396\tvalid_1's l1: 6.23414\n",
      "[800]\ttraining's l1: 6.1582\tvalid_1's l1: 6.23162\n",
      "[850]\ttraining's l1: 6.1534\tvalid_1's l1: 6.22973\n",
      "[900]\ttraining's l1: 6.14778\tvalid_1's l1: 6.22725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.14778\tvalid_1's l1: 6.22725\n",
      "Fold 1 Trainning finished.\n",
      "############mae##############: 6.227245727142715\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19778\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.238484 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.33117\tvalid_1's l1: 6.33431\n",
      "[100]\ttraining's l1: 6.29279\tvalid_1's l1: 6.30025\n",
      "[150]\ttraining's l1: 6.2709\tvalid_1's l1: 6.28271\n",
      "[200]\ttraining's l1: 6.25631\tvalid_1's l1: 6.27237\n",
      "[250]\ttraining's l1: 6.2451\tvalid_1's l1: 6.26545\n",
      "[300]\ttraining's l1: 6.23567\tvalid_1's l1: 6.26017\n",
      "[350]\ttraining's l1: 6.22647\tvalid_1's l1: 6.25504\n",
      "[400]\ttraining's l1: 6.21755\tvalid_1's l1: 6.25002\n",
      "[450]\ttraining's l1: 6.20889\tvalid_1's l1: 6.24516\n",
      "[500]\ttraining's l1: 6.20049\tvalid_1's l1: 6.2405\n",
      "[550]\ttraining's l1: 6.1926\tvalid_1's l1: 6.23625\n",
      "[600]\ttraining's l1: 6.18542\tvalid_1's l1: 6.2326\n",
      "[650]\ttraining's l1: 6.1784\tvalid_1's l1: 6.2292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\ttraining's l1: 6.17199\tvalid_1's l1: 6.22619\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[750]\ttraining's l1: 6.16632\tvalid_1's l1: 6.22381\n",
      "[800]\ttraining's l1: 6.16064\tvalid_1's l1: 6.22142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's l1: 6.15585\tvalid_1's l1: 6.21958\n",
      "[900]\ttraining's l1: 6.15049\tvalid_1's l1: 6.21725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.15049\tvalid_1's l1: 6.21725\n",
      "Fold 2 Trainning finished.\n",
      "############mae##############: 6.217247385223134\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.219688 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.33214\tvalid_1's l1: 6.329\n",
      "[100]\ttraining's l1: 6.29391\tvalid_1's l1: 6.29445\n",
      "[150]\ttraining's l1: 6.27225\tvalid_1's l1: 6.27657\n",
      "[200]\ttraining's l1: 6.25777\tvalid_1's l1: 6.26587\n",
      "[250]\ttraining's l1: 6.24673\tvalid_1's l1: 6.25863\n",
      "[300]\ttraining's l1: 6.2371\tvalid_1's l1: 6.25295\n",
      "[350]\ttraining's l1: 6.22803\tvalid_1's l1: 6.24767\n",
      "[400]\ttraining's l1: 6.21906\tvalid_1's l1: 6.24242\n",
      "[450]\ttraining's l1: 6.21052\tvalid_1's l1: 6.23778\n",
      "[500]\ttraining's l1: 6.2027\tvalid_1's l1: 6.23372\n",
      "[550]\ttraining's l1: 6.19532\tvalid_1's l1: 6.23007\n",
      "[600]\ttraining's l1: 6.18808\tvalid_1's l1: 6.22658\n",
      "[650]\ttraining's l1: 6.18128\tvalid_1's l1: 6.22343\n",
      "[700]\ttraining's l1: 6.17485\tvalid_1's l1: 6.22042\n",
      "[750]\ttraining's l1: 6.16914\tvalid_1's l1: 6.21793\n",
      "[800]\ttraining's l1: 6.16357\tvalid_1's l1: 6.21571\n",
      "[850]\ttraining's l1: 6.15903\tvalid_1's l1: 6.21412\n",
      "[900]\ttraining's l1: 6.15399\tvalid_1's l1: 6.21215\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.15399\tvalid_1's l1: 6.21215\n",
      "Fold 3 Trainning finished.\n",
      "############mae##############: 6.212145880175026\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19780\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.222886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.33004\tvalid_1's l1: 6.33941\n",
      "[100]\ttraining's l1: 6.29196\tvalid_1's l1: 6.30477\n",
      "[150]\ttraining's l1: 6.27039\tvalid_1's l1: 6.28686\n",
      "[200]\ttraining's l1: 6.25598\tvalid_1's l1: 6.27622\n",
      "[250]\ttraining's l1: 6.24487\tvalid_1's l1: 6.26897\n",
      "[300]\ttraining's l1: 6.23534\tvalid_1's l1: 6.26327\n",
      "[350]\ttraining's l1: 6.22608\tvalid_1's l1: 6.25787\n",
      "[400]\ttraining's l1: 6.21708\tvalid_1's l1: 6.25259\n",
      "[450]\ttraining's l1: 6.20841\tvalid_1's l1: 6.24776\n",
      "[500]\ttraining's l1: 6.20046\tvalid_1's l1: 6.24359\n",
      "[550]\ttraining's l1: 6.19269\tvalid_1's l1: 6.23956\n",
      "[600]\ttraining's l1: 6.18591\tvalid_1's l1: 6.23635\n",
      "[650]\ttraining's l1: 6.1799\tvalid_1's l1: 6.23393\n",
      "[700]\ttraining's l1: 6.17361\tvalid_1's l1: 6.23113\n",
      "[750]\ttraining's l1: 6.16776\tvalid_1's l1: 6.22856\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\ttraining's l1: 6.16325\tvalid_1's l1: 6.22664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's l1: 6.15862\tvalid_1's l1: 6.22456\n",
      "[900]\ttraining's l1: 6.15404\tvalid_1's l1: 6.22258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.15404\tvalid_1's l1: 6.22258\n",
      "Fold 4 Trainning finished.\n",
      "############mae##############: 6.222576298992452\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19779\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.304469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.33198\tvalid_1's l1: 6.33023\n",
      "[100]\ttraining's l1: 6.29366\tvalid_1's l1: 6.2962\n",
      "[150]\ttraining's l1: 6.27193\tvalid_1's l1: 6.27859\n",
      "[200]\ttraining's l1: 6.25738\tvalid_1's l1: 6.26807\n",
      "[250]\ttraining's l1: 6.24632\tvalid_1's l1: 6.26107\n",
      "[300]\ttraining's l1: 6.23675\tvalid_1's l1: 6.25553\n",
      "[350]\ttraining's l1: 6.22757\tvalid_1's l1: 6.25027\n",
      "[400]\ttraining's l1: 6.21879\tvalid_1's l1: 6.24523\n",
      "[450]\ttraining's l1: 6.21037\tvalid_1's l1: 6.24082\n",
      "[500]\ttraining's l1: 6.20213\tvalid_1's l1: 6.23645\n",
      "[550]\ttraining's l1: 6.19448\tvalid_1's l1: 6.23263\n",
      "[600]\ttraining's l1: 6.18767\tvalid_1's l1: 6.2293\n",
      "[650]\ttraining's l1: 6.18097\tvalid_1's l1: 6.22624\n",
      "[700]\ttraining's l1: 6.17468\tvalid_1's l1: 6.22355\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[750]\ttraining's l1: 6.16882\tvalid_1's l1: 6.22097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\ttraining's l1: 6.16259\tvalid_1's l1: 6.2182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's l1: 6.15741\tvalid_1's l1: 6.21601\n",
      "[900]\ttraining's l1: 6.15258\tvalid_1's l1: 6.2143\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.15258\tvalid_1's l1: 6.2143\n",
      "Fold 5 Trainning finished.\n",
      "############mae##############: 6.2143045376441135\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 19779\n",
      "[LightGBM] [Info] Number of data points in the train set: 4364910, number of used features: 84\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 84 dense feature groups (349.67 MB) transferred to GPU in 0.220121 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's l1: 6.33182\tvalid_1's l1: 6.33113\n",
      "[100]\ttraining's l1: 6.29344\tvalid_1's l1: 6.2966\n",
      "[150]\ttraining's l1: 6.27193\tvalid_1's l1: 6.27891\n",
      "[200]\ttraining's l1: 6.25747\tvalid_1's l1: 6.2684\n",
      "[250]\ttraining's l1: 6.2464\tvalid_1's l1: 6.26128\n",
      "[300]\ttraining's l1: 6.23676\tvalid_1's l1: 6.25569\n",
      "[350]\ttraining's l1: 6.22778\tvalid_1's l1: 6.25059\n",
      "[400]\ttraining's l1: 6.21861\tvalid_1's l1: 6.24526\n",
      "[450]\ttraining's l1: 6.21007\tvalid_1's l1: 6.24056\n",
      "[500]\ttraining's l1: 6.20214\tvalid_1's l1: 6.23646\n",
      "[550]\ttraining's l1: 6.19495\tvalid_1's l1: 6.23268\n",
      "[600]\ttraining's l1: 6.18796\tvalid_1's l1: 6.22926\n",
      "[650]\ttraining's l1: 6.18157\tvalid_1's l1: 6.22645\n",
      "[700]\ttraining's l1: 6.17535\tvalid_1's l1: 6.22367\n",
      "[750]\ttraining's l1: 6.16953\tvalid_1's l1: 6.22144\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\ttraining's l1: 6.16415\tvalid_1's l1: 6.21921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's l1: 6.15915\tvalid_1's l1: 6.21706\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\ttraining's l1: 6.15401\tvalid_1's l1: 6.21493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's l1: 6.15401\tvalid_1's l1: 6.21493\n",
      "Fold 6 Trainning finished.\n",
      "############mae##############: 6.2149267971948\n",
      "6 fold MAE: 6.218074437728707\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=N_Folds, shuffle=True, random_state=100)\n",
    "mae_scores = []\n",
    "\n",
    "if is_train:\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "        m = lgb.train(params, train_data, valid_sets=[train_data, valid_data],verbose_eval=50, early_stopping_rounds=50)\n",
    "        print(f\"Fold {fold+1} Trainning finished.\")\n",
    "\n",
    "        model_filename = f\"/kaggle/working/model_fold_{fold+1}.pkl\"\n",
    "        joblib.dump(m, model_filename)\n",
    "        y_pred_valid = m.predict(X_valid)\n",
    "\n",
    "        y_pred_valid = np.nan_to_num(y_pred_valid)\n",
    "        y_valid = np.nan_to_num(y_valid)\n",
    "        mae = mean_absolute_error(y_valid, y_pred_valid)\n",
    "        print(\"############mae##############:\",mae)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # 计算4折平均的MAE\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    print(f\"{N_Folds} fold MAE: {average_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab63d91c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-24T01:42:12.328266Z",
     "iopub.status.busy": "2023-10-24T01:42:12.327913Z",
     "iopub.status.idle": "2023-10-24T01:45:47.806100Z",
     "shell.execute_reply": "2023-10-24T01:45:47.805282Z"
    },
    "papermill": {
     "duration": 215.497921,
     "end_time": "2023-10-24T01:45:47.808512",
     "exception": false,
     "start_time": "2023-10-24T01:42:12.310591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    return out\n",
    "\n",
    "if is_infer:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "\n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        feat = feature_eng(test)\n",
    "        fold_prediction = 0\n",
    "        for fold in range(0, N_Folds):\n",
    "            model_filename = f\"/kaggle/working/model_fold_{fold+1}.pkl\"\n",
    "            m = joblib.load(model_filename)\n",
    "            fold_prediction += m.predict(feat, predict_disable_shape_check=True)   \n",
    "        \n",
    "        fold_prediction /= N_Folds\n",
    "        fold_prediction = zero_sum(fold_prediction, test.loc[:,'bid_size'] + test.loc[:,'ask_size'])\n",
    "        clipped_predictions = np.clip(fold_prediction, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3238.2304,
   "end_time": "2023-10-24T01:45:49.154930",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-24T00:51:50.924530",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
